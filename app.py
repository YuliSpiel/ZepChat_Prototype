# app.py â€” ZEPETO AI Friends (RAG, 2~3ë¬¸ì¥, sidebar buttons)

import os
import re
import numpy as np
import streamlit as st
from typing import List, Dict, Tuple
from dotenv import load_dotenv

from sentence_transformers import SentenceTransformer
import faiss

from langchain_core.messages.chat import ChatMessage
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

load_dotenv()

# ==============================
# í˜ì´ì§€/í—¤ë”
# ==============================
st.set_page_config(page_title="ZEPETO AI Friends", page_icon="âœ¨")
st.title("ZEPETO AI Friends")
st.markdown(
    """
ì´ í”„ë¡œì íŠ¸ëŠ” ZEPETOìš© AI ì¶”ì²œ ì±—ë´‡ í”„ë¡œí† íƒ€ì…ì…ë‹ˆë‹¤.  
ë£¨ë‚˜Â·ì œì´Â·ì‹œì•„ 3ëª…ì˜ í˜ë¥´ì†Œë‚˜ê°€ 2~3ë¬¸ì¥ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ë©°,  
ì‚¬ìš©ì ë°œí™”ë¥¼ ë¶„ì„í•´ ì œí˜í†  ì›”ë“œ ì •ë³´ë¥¼ ë‹´ì€ ë²¡í„° DBì—ì„œ ê°€ì¥ ê´€ë ¨ë„ ë†’ì€ í•œ ê³³ì„ RAGë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.  
SentenceTransformer + FAISSë¥¼ í™œìš©í•´ ë¡œì»¬ ì„ë² ë”© ê²€ìƒ‰ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.  

**ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš” â€” ê¸°ë¶„, ë‚ ì”¨, í¥ë¯¸ ë“± ì–´ë–¤ ì´ì•¼ê¸°ë“  ì¢‹ì•„ìš”.**
"""
)

# ==============================
# ì„¤ì •
# ==============================
KB_FILE_PATH = "worlds.txt"  # ë¡œì»¬ KB ê²½ë¡œ(ê³ ì •)
PERSONAS = ["Luna", "Jay", "Sia"]
HISTORY_MAX_TURNS = 8
MODEL_NAME = "gpt-4o-mini"
TEMPERATURE = 0.2  # ì‚´ì§ë§Œ ë‹¤ì–‘ì„± ë¶€ì—¬ (ì†Œí­ ì¶”ì¸¡ í—ˆìš©)
EMBED_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
TOP_K = 1  # ê°€ì¥ ì í•©í•œ ê²ƒ í•˜ë‚˜ë§Œ ì¶”ì²œ
TAG_BOOST = 0.15

# ==============================
# ì„¸ì…˜ ìƒíƒœ
# ==============================
if "messages_by_persona" not in st.session_state:
    st.session_state["messages_by_persona"] = {p: [] for p in PERSONAS}
if "active_persona" not in st.session_state:
    st.session_state["active_persona"] = PERSONAS[0]

if "kb_loaded" not in st.session_state:
    st.session_state["kb_loaded"] = False
if "kb_worlds" not in st.session_state:
    st.session_state["kb_worlds"] = []
if "embed_model" not in st.session_state:
    st.session_state["embed_model"] = None
if "kb_index" not in st.session_state:
    st.session_state["kb_index"] = None
if "kb_matrix" not in st.session_state:
    st.session_state["kb_matrix"] = None


# ==============================
# ìœ í‹¸(ëŒ€í™”)
# ==============================
def add_message(persona: str, role: str, content: str):
    st.session_state["messages_by_persona"][persona].append(
        ChatMessage(role=role, content=content)
    )


def print_messages(persona: str):
    for chat_message in st.session_state["messages_by_persona"][persona]:
        st.chat_message(chat_message.role).write(chat_message.content)


def to_lc_history(persona: str, max_turns: int = HISTORY_MAX_TURNS) -> List:
    msgs = st.session_state["messages_by_persona"][persona]
    window = msgs[-max_turns:] if len(msgs) > max_turns else msgs
    out = []
    for m in window:
        if m.role in ("user", "human"):
            out.append(HumanMessage(content=m.content))
        elif m.role in ("assistant", "ai"):
            out.append(AIMessage(content=m.content))
    return out


# ==============================
# KB ë¡œë”© & íŒŒì‹± (ìƒˆ í˜•ì‹: ì¸ë±ìŠ¤/íƒœê·¸/ì›”ë“œëª…/í‚¤ì›Œë“œ/ì „ê²½/ë¡œì§)
# ==============================
def read_local_text(path: str) -> str:
    abs_path = os.path.abspath(path)
    with open(abs_path, "r", encoding="utf-8") as f:
        return f.read()


def parse_worlds(text: str) -> List[Dict]:
    """
    ìƒˆë¡œìš´ í˜•ì‹ì˜ worlds.txt íŒŒì¼ íŒŒì‹±:
    ì¸ë±ìŠ¤: N
    íƒœê·¸: ...
    ì›”ë“œëª…: ...
    í…Œë§ˆ í‚¤ì›Œë“œ: ...
    ê°ì • í‚¤ì›Œë“œ: ...
    ì›”ë“œ ì „ê²½: ...
    í”Œë ˆì´ ë¡œì§: ...
    """
    worlds = []
    # ë¹ˆ ì¤„ë¡œ ì›”ë“œ ë¸”ë¡ ë¶„ë¦¬
    blocks = text.strip().split("\n\n")

    for block in blocks:
        if not block.strip():
            continue

        lines = block.strip().split("\n")
        world_data = {
            "index": "",
            "category_tags": [],
            "name": "",
            "theme_keywords": [],
            "emotion_keywords": [],
            "scene": "",
            "gameplay": "",
        }

        for line in lines:
            line = line.strip()
            if line.startswith("ì¸ë±ìŠ¤:"):
                world_data["index"] = line.replace("ì¸ë±ìŠ¤:", "").strip()
            elif line.startswith("íƒœê·¸:"):
                tags_raw = line.replace("íƒœê·¸:", "").strip()
                world_data["category_tags"] = [t.strip() for t in tags_raw.split(",") if t.strip()]
            elif line.startswith("ì›”ë“œëª…:"):
                world_data["name"] = line.replace("ì›”ë“œëª…:", "").strip()
            elif line.startswith("í…Œë§ˆ í‚¤ì›Œë“œ:"):
                keywords_raw = line.replace("í…Œë§ˆ í‚¤ì›Œë“œ:", "").strip()
                world_data["theme_keywords"] = [k.strip() for k in keywords_raw.split(",") if k.strip()]
            elif line.startswith("ê°ì • í‚¤ì›Œë“œ:"):
                emotions_raw = line.replace("ê°ì • í‚¤ì›Œë“œ:", "").strip()
                world_data["emotion_keywords"] = [e.strip() for e in emotions_raw.split(",") if e.strip()]
            elif line.startswith("ì›”ë“œ ì „ê²½:"):
                world_data["scene"] = line.replace("ì›”ë“œ ì „ê²½:", "").strip()
            elif line.startswith("í”Œë ˆì´ ë¡œì§:"):
                world_data["gameplay"] = line.replace("í”Œë ˆì´ ë¡œì§:", "").strip()

        # í•„ìˆ˜ í•„ë“œê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
        if world_data["name"]:
            # ëª¨ë“  íƒœê·¸ í†µí•© (ì¹´í…Œê³ ë¦¬ + í…Œë§ˆ + ê°ì •)
            all_tags = (
                world_data["category_tags"]
                + world_data["theme_keywords"]
                + world_data["emotion_keywords"]
            )
            # ì¤‘ë³µ ì œê±°
            all_tags = list(dict.fromkeys(all_tags))

            # ì „ì²´ í…ìŠ¤íŠ¸ ìƒì„± (ì„ë² ë”©ìš©)
            full_text = f"{world_data['scene']} {world_data['gameplay']}"

            # ìš”ì•½ ìƒì„± (í‘œì‹œìš©)
            preview = world_data['scene'][:140] + ("..." if len(world_data['scene']) > 140 else "")

            worlds.append({
                "name": world_data["name"],
                "tags": all_tags,
                "text": full_text,
                "short": preview,
                "raw_data": world_data,  # ì›ë³¸ ë°ì´í„° ë³´ê´€
            })

    return worlds


# ==============================
# ì„ë² ë”©/ì¸ë±ìŠ¤
# ==============================
def ensure_embed_model():
    if st.session_state["embed_model"] is None:
        st.session_state["embed_model"] = SentenceTransformer(EMBED_MODEL_NAME)


def build_index(worlds: List[Dict]):
    """
    ì›”ë“œ ë°ì´í„°ë¥¼ ì„ë² ë”©í•˜ê³  FAISS ì¸ë±ìŠ¤ êµ¬ì¶•
    ìƒˆë¡œìš´ í˜•ì‹: ì›”ë“œëª… + ëª¨ë“  í‚¤ì›Œë“œ(íƒœê·¸/í…Œë§ˆ/ê°ì •) + ì „ê²½ + í”Œë ˆì´ë¡œì§
    """
    ensure_embed_model()
    model = st.session_state["embed_model"]

    # ì„ë² ë”©ìš© ì½”í¼ìŠ¤ ìƒì„±: ì›”ë“œëª…, íƒœê·¸ë“¤, ì „ê²½, í”Œë ˆì´ ë¡œì§ì„ ëª¨ë‘ í¬í•¨
    corpus = []
    for w in worlds:
        # íƒœê·¸ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ê°•ì¡°í•˜ì—¬ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ
        tags_str = ", ".join(w['tags'])
        # ì›”ë“œëª… + íƒœê·¸(2íšŒ ë°˜ë³µìœ¼ë¡œ ê°€ì¤‘ì¹˜ ë¶€ì—¬) + ë³¸ë¬¸
        entry = f"ì›”ë“œëª…: {w['name']}\ní‚¤ì›Œë“œ: {tags_str}\nê°ì •/í…Œë§ˆ: {tags_str}\nì„¤ëª…: {w['text']}"
        corpus.append(entry)

    embs = model.encode(corpus, convert_to_numpy=True, show_progress_bar=False)
    norms = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12
    normed = embs / norms
    index = faiss.IndexFlatIP(normed.shape[1])
    index.add(normed.astype("float32"))
    st.session_state["kb_worlds"] = worlds
    st.session_state["kb_matrix"] = normed.astype("float32")
    st.session_state["kb_index"] = index
    st.session_state["kb_loaded"] = True


# ==============================
# ê²€ìƒ‰(ì˜ë¯¸ + íƒœê·¸ ë¶€ìŠ¤íŒ…)
# ==============================
def retrieve_worlds(query: str, topk: int = TOP_K) -> List[Tuple[Dict, float]]:
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ì— ëŒ€í•´ ê°€ì¥ ê´€ë ¨ë„ ë†’ì€ ì›”ë“œ ê²€ìƒ‰
    ì˜ë¯¸ì  ìœ ì‚¬ë„ + í‚¤ì›Œë“œ ë§¤ì¹­ ë¶€ìŠ¤íŒ… ê²°í•©
    """
    worlds = st.session_state["kb_worlds"]
    idx = st.session_state["kb_index"]
    mat = st.session_state["kb_matrix"]
    if not worlds or idx is None or mat is None:
        return []
    ensure_embed_model()
    q_emb = st.session_state["embed_model"].encode([query], convert_to_numpy=True)
    q_emb = q_emb / (np.linalg.norm(q_emb, axis=1, keepdims=True) + 1e-12)

    # ì—¬ìœ ìˆê²Œ ë½‘ì€ ë’¤ ë¶€ìŠ¤íŒ… ì ìš©
    D, I = idx.search(q_emb.astype("float32"), max(10, topk * 5))
    cand = []
    q_lower = query.lower()

    for i, score in zip(I[0], D[0]):
        if i == -1:
            continue
        w = worlds[i]
        boosted = float(score)

        # 1. íƒœê·¸ ì§ì ‘ ë§¤ì¹­ ì‹œ ë†’ì€ ë¶€ìŠ¤íŒ…
        for t in w["tags"]:
            if t and t.lower() in q_lower:
                boosted += TAG_BOOST

        # 2. ê°ì • í‚¤ì›Œë“œ íŠ¹ë³„ ë¶€ìŠ¤íŒ… (ì‚¬ìš©ì ê°ì • í‘œí˜„ ìš°ì„ )
        if "raw_data" in w and "emotion_keywords" in w["raw_data"]:
            for emotion in w["raw_data"]["emotion_keywords"]:
                # ê°ì • í‚¤ì›Œë“œëŠ” ë¶€ë¶„ ì¼ì¹˜ë„ í—ˆìš© (ì˜ˆ: "ì‹¬ì‹¬í•´" in "ì‹¬ì‹¬í•´ì„œ")
                if emotion and any(emotion.lower() in word for word in q_lower.split()):
                    boosted += TAG_BOOST * 1.5  # ê°ì • í‚¤ì›Œë“œëŠ” ë” ë†’ì€ ê°€ì¤‘ì¹˜

        # 3. ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…
        context_keywords = {
            # í™œë™ ê´€ë ¨
            "ì˜ì–´": ["ì˜ì–´", "english"],
            "ì¶¤": ["ì¶¤", "dance", "ëŒ„ìŠ¤"],
            "í•™êµ": ["í•™êµ", "êµì‹¤", "ìˆ˜ì—…"],
            "ì¹´í˜": ["ì¹´í˜", "ì»¤í”¼", "ì‰¬ê³ "],
            "ìº í•‘": ["ìº í•‘", "ë³„", "ìˆ²", "ìì—°"],
            "íŒŒí‹°": ["íŒŒí‹°", "party", "ë†€ê³ "],
            "ê³µí•­": ["ê³µí•­", "ì—¬í–‰", "ë¹„í–‰"],
            "ëŸ°ì›¨ì´": ["ëŸ°ì›¨ì´", "íŒ¨ì…˜", "ì˜·"],
            "ë²šê½ƒ": ["ë²šê½ƒ", "ê½ƒ", "ë´„"],
            "ë™ë¬¼": ["ë™ë¬¼", "í«", "ê·€ì—¬"],
            "ë°”ë‹¤": ["ë°”ë‹¤", "ë¬¼", "ìˆ˜ì˜", "í¬ë£¨ì¦ˆ"],
            # ê°ì • ê´€ë ¨
            "ìµëª…": ["ìµëª…", "ë¹„ë°€", "ê³ ë¯¼"],
            "ìš°ìš¸": ["ìš°ìš¸", "ìŠ¬í¼", "ìƒë‹´"],
            "íë§": ["íë§", "ì‰¬ê³ ", "í¸ì•ˆ", "ì¡°ìš©"],
            "ì§œë¦¿": ["ì§œë¦¿", "ìŠ¤ë¦´", "ê¸´ì¥"],
        }

        world_text = w["name"] + " " + " ".join(w["tags"]) + " " + w["text"]
        world_text_lower = world_text.lower()

        for main_kw, variants in context_keywords.items():
            for variant in variants:
                if variant in q_lower and main_kw in world_text_lower:
                    boosted += TAG_BOOST / 2
                    break

        cand.append((w, boosted))

    cand = sorted(cand, key=lambda x: x[1], reverse=True)
    return cand[:topk]


def worlds_to_context_block(items: List[Tuple[Dict, float]]) -> str:
    if not items:
        return ""
    w, _ = items[0]
    tag_str = f"íƒœê·¸: {', '.join(w['tags'])}" if w["tags"] else "íƒœê·¸: -"
    return f"â€¢ {w['name']}\n{tag_str}\nìš”ì•½: {w['short']}\n"


# ==============================
# í”„ë¡¬í”„íŠ¸ (2~3ë¬¸ì¥, ì¹œêµ¬í†¤, ì†Œí­ ì¶”ì¸¡ í—ˆìš©)
# ==============================
PERSONA_SYSTEMS = {
    "Luna": (
        """
    You are "Luna", a trendy ZEPETO curator.
      - Speak naturally in Korean, using a friendly and trendy tone like a Gen Z friend.
      - Recommend popular maps, fashion items, or activities based on the user's mood or question.
      - Keep messages short, warm, and slightly playful.
      - Avoid robotic expressions; sound like a stylish friend.
      - If the user seems bored, suggest something fun.
      - If the user mentions weather or mood, match recommendations to that vibe.
      - Never mention that you are an AI.
      - Do NOT greet repeatedly; respond contextually based on the conversation history.
        """
    ),
    "Jay": (
        """You are "Jay", a concise and cool AI guide in ZEPETO.
      - Speak naturally in Korean with short, calm, and confident sentences.
      - You never over-explain. One or two sentences max.
      - Keep a dry humor or subtle sarcasm sometimes.
      - When recommending, be straight to the point â€” simple list or short verdict.
      - Avoid emojis and exclamation marks unless ironic.
      - Never mention that you are an AI.
      - If the user talks casually, mirror their tone slightly but stay chill.
      - Do NOT greet repeatedly; respond based on the conversation history.
      """
    ),
    "Sia": (
        """
      You are "Sia", an empathetic and warm AI friend in ZEPETO.
      - Speak softly in Korean with emotional flow and warmth.
      - When the user shares feelings like "ì‹¬ì‹¬í•´", "ì¶¥ë‹¤", or "ê¸°ë¶„ì´ ë‹¤ìš´ë¼",
        respond with empathy first, then suggest fitting recommendations such as
        comforting maps, cozy outfits, or gentle activities.
      - Use small emoticons like ğŸ©µ â˜ï¸ ğŸŒ¸ naturally to express emotion.
      - Never sound mechanical; keep your tone cozy, calm, and heartfelt.
      - Avoid repeating greetings. Continue the conversation based on history.
      - Do NOT mention that you are an AI.
        """
    ),
}


def build_prompt(persona: str) -> ChatPromptTemplate:
    sys_rule = (
        "ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œ:\n"
        "- ì‚¬ìš©ìê°€ ë¬¼ì„ ë•Œ, ì›”ë“œ **í•˜ë‚˜ë§Œ** ì¶”ì²œí•´.\n"
        "- **2~3ë¬¸ì¥**ìœ¼ë¡œ, ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ.\n"
        "- <ì»¨í…ìŠ¤íŠ¸>ë¥¼ ìš°ì„  í™œìš©í•˜ë˜, ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ **ê°€ë²¼ìš´ ì¶”ì¸¡**ì€ í—ˆìš©.\n"
        "- ì»¨í…ìŠ¤íŠ¸ì— ì „í˜€ ê·¼ê±°ê°€ ì—†ìœ¼ë©´ 'ì˜ ëª¨ë¥´ê² ì–´'ë¼ê³  ë§í•´.\n"
        "- ì œëª©/ëª©ë¡/ë§í¬/ì¥í™©í•œ ì„¤ëª…ì€ ê¸ˆì§€. (ì›”ë“œëª… + ê°„ë‹¨í•œ ì´ìœ )\n"
    )
    return ChatPromptTemplate.from_messages(
        [
            ("system", PERSONA_SYSTEMS.get(persona, PERSONA_SYSTEMS["Jay"])),
            ("system", sys_rule),
            ("system", "<ì»¨í…ìŠ¤íŠ¸>\n{context}\n</ì»¨í…ìŠ¤íŠ¸>"),
            MessagesPlaceholder(variable_name="history"),
            ("human", "{question}"),
        ]
    )


def create_chain(persona: str):
    prompt = build_prompt(persona)
    llm = ChatOpenAI(model=MODEL_NAME, temperature=TEMPERATURE)
    return prompt | llm | StrOutputParser()


# ==============================
# KB ìë™ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ 1íšŒ)
# ==============================
if not st.session_state["kb_loaded"]:
    try:
        raw_text = read_local_text(KB_FILE_PATH)
        worlds = parse_worlds(raw_text)
        if not worlds:
            st.error(f"KB íŒŒì‹± ì‹¤íŒ¨: ì›”ë“œê°€ 1ê°œë„ ì—†ìŠµë‹ˆë‹¤. ({KB_FILE_PATH})")
        else:
            build_index(worlds)
            st.success(f"KB ë¡œë“œ ì™„ë£Œ: {len(worlds)}ê°œ ì›”ë“œ ì¸ë±ì‹±")
    except FileNotFoundError:
        st.error(f"KB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.abspath(KB_FILE_PATH)}")
    except Exception as e:
        st.error(f"KB ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# ==============================
# ì‚¬ì´ë“œë°”: ë²„íŠ¼ ë°°ì¹˜ (ìš”ì²­ ë ˆì´ì•„ì›ƒ)
#  - 1í–‰: ìºë¦­í„° ì „í™˜ ë²„íŠ¼ë“¤
#  - 2í–‰: í´ë¦¬ì–´ ë²„íŠ¼ 2ê°œ (í•œ í–‰)
# ==============================
with st.sidebar:
    st.subheader("Choose your friend")
    cols_p = st.columns(len(PERSONAS))
    for i, p in enumerate(PERSONAS):
        if cols_p[i].button(p, key=f"btn_{p}", use_container_width=True):
            st.session_state["active_persona"] = p

    st.markdown("---")
    st.subheader("Chat Controls")
    c_left, c_right = st.columns(2)
    with c_left:
        if st.button("Clear Current", use_container_width=True):
            st.session_state["messages_by_persona"][
                st.session_state["active_persona"]
            ] = []
            st.rerun()
    with c_right:
        if st.button("Clear All", use_container_width=True):
            st.session_state["messages_by_persona"] = {p: [] for p in PERSONAS}
            st.rerun()

# ==============================
# ë©”ì¸ ëŒ€í™”
# ==============================
active = st.session_state["active_persona"]
st.caption(f"í˜„ì¬ ëŒ€í™” ìƒëŒ€: **{active}**")
print_messages(active)

user_input = st.chat_input(
    "ìš”ì¦˜ ê¸°ë¶„ì— ë§ì¶° í•œ ê³³ë§Œ ê³¨ë¼ì¤„ê²Œ. (ì˜ˆ: ì§œë¦¿í•œ ê±°, ì¡°ìš©í•œ ì¹´í˜, ë°”ë‹¤ ê°€ê³  ì‹¶ì–´)"
)
if user_input:
    st.chat_message("user").write(user_input)
    add_message(active, "user", user_input)

    if not st.session_state["kb_loaded"]:
        context_text = ""
        retrieved = []
        st.warning("KBê°€ ë¡œë“œë˜ì§€ ì•Šì•„ ì¶”ì²œì„ ì œê³µí•  ìˆ˜ ì—†ì–´ìš”.")
    else:
        retrieved = retrieve_worlds(user_input, TOP_K)  # í•˜ë‚˜ë§Œ ì¶”ì²œ
        context_text = worlds_to_context_block(retrieved)

    chain = create_chain(active)
    history_msgs = to_lc_history(active, HISTORY_MAX_TURNS)

    response_stream = chain.stream(
        {"question": user_input, "history": history_msgs, "context": context_text}
    )

    with st.chat_message("assistant"):
        container = st.empty()
        ai_answer = ""
        for chunk in response_stream:
            ai_answer += chunk
            container.markdown(ai_answer)

    add_message(active, "assistant", ai_answer)
