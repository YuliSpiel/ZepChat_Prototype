# app.py â€” ZEPETO AI Friends
# RAG(FAISS) + CSV KB + LLM Intent Routing(2-shot)
# + Topic Guard + Confidence Throttle + Heuristic Override + Safe Smalltalk

import os
import csv
import re
import numpy as np
import streamlit as st
from typing import List, Dict, Tuple
from dotenv import load_dotenv

from sentence_transformers import SentenceTransformer
import faiss

from langchain_core.messages.chat import ChatMessage
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser

load_dotenv()

# ==============================
# í˜ì´ì§€/í—¤ë”
# ==============================
st.set_page_config(page_title="ZEPETO AI Friends", page_icon="âœ¨")
st.title("ZEPETO AI Friends")
st.markdown(
    """
ì´ í”„ë¡œì íŠ¸ëŠ” ZEPETOìš© AI ì¶”ì²œ ì±—ë´‡ í”„ë¡œí† íƒ€ì…ì…ë‹ˆë‹¤.  
ë£¨ë‚˜Â·ì œì´Â·ì‹œì•„ 3ëª…ì˜ í˜ë¥´ì†Œë‚˜ê°€ 2~3ë¬¸ì¥ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ë©°,  
ì‚¬ìš©ì ë°œí™”ë¥¼ ë¶„ì„í•´ **CSV ì§€ì‹ë² ì´ìŠ¤(worlds.csv)** ì—ì„œ ê°€ì¥ ê´€ë ¨ë„ ë†’ì€ **í•œ ê³³**ì„ RAGë¡œ ì¶”ì²œí•©ë‹ˆë‹¤.  
SentenceTransformer + FAISS ë¡œì»¬ ì„ë² ë”© ê²€ìƒ‰ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""
)

# ==============================
# ì„¤ì •
# ==============================
KB_FILE_PATH = "worlds.csv"  # âœ… CSV ì§€ì‹ë² ì´ìŠ¤ ê²½ë¡œ (title,concept,contents,situations,emotions,tags)
PERSONAS = ["Luna", "Jay", "Sia"]
HISTORY_MAX_TURNS = 8
MODEL_NAME = "gpt-4o-mini"
TEMPERATURE = 0.2
EMBED_MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
TOP_K = 1

# ê²€ìƒ‰/ë§¤ì¹­ íŒŒë¼ë¯¸í„°
TAG_BOOST = 0.25  # íƒœê·¸/ìƒí™©/ê°ì • í‚¤ì›Œë“œ ë¶€ìŠ¤íŒ…
MIN_CONF_SCORE = 0.25  # ì¶”ì²œ ìµœì†Œ ì‹ ë¢°ë„(ë¶€ìŠ¤íŒ… í›„)
MIN_MARGIN = 0.05  # Top1 - Top2 ìµœì†Œ ê²©ì°¨(ë‚®ìœ¼ë©´ ë¶ˆí™•ì‹¤)

# í† í”½ ê·¸ë£¹(ë™ì˜ì–´Â·ì—°ê´€ì–´) â€” í•„ìš” ì‹œ ììœ ë¡­ê²Œ í™•ì¥
TOPIC_GROUPS = {
    "sea": ["ë°”ë‹¤", "ì˜¤ì…˜", "í¬ë£¨ì¦ˆ", "ìˆ˜ì˜", "ì›Œí„°", "ì›Œí„°ìŠ¬ë¼ì´ë“œ", "íŠœë¸Œ", "ìœ ìŠ¤í’€"],
    "runway": ["ëŸ°ì›¨ì´", "íŒ¨ì…˜", "íŒ¨ì…˜ì‡¼", "ì•„ë””ë‹¤ìŠ¤", "itzy", "ì›Œí‚¹", "í¬ì¦ˆ"],
    "school": ["í•™êµ", "êµì‹¤", "ê¸‰ì‹ì‹¤", "ì‹¤í—˜", "ìíŒê¸°", "ì˜¥ìƒ"],
    "cafe": ["ì¹´í˜", "ì»¤í”¼", "ë£¨í”„íƒ‘", "ì¡°ëª…", "ì†ŒíŒŒ"],
    "wedding": ["ì›¨ë”©", "ê²°í˜¼ì‹", "ë¶€ì¼€", "ë ˆë“œì¹´í«", "í•˜ê°"],
    "camp": ["ìº í•‘", "ìº í”„íŒŒì´ì–´", "ë³„", "ì˜¤ë¡œë¼", "ë‚šì‹œ"],
    "animal": ["ë™ë¬¼", "êµ¬ì¡°", "íƒí—˜"],
    "airport": ["ê³µí•­", "ëŒ€í•©ì‹¤", "ì¶œêµ­", "ê¸°ë‚´ì‹", "ë¹„í–‰ê¸°", "í¬íƒˆ", "íŒŒí‹°"],
    "prison": ["ê°ì˜¥", "íƒˆì¶œ", "ê²½ì°°", "ì£„ìˆ˜", "ë¹„ë°€ í†µë¡œ", "ìˆ˜ê°‘"],
    "cherry": ["ë²šê½ƒ", "ì˜¨ì²œ", "ì—°ëª»", "ì–‘ì‚°", "ì „í†µì˜ìƒ"],
    "anon": ["ìµëª…", "ê³ ë¯¼", "ìƒë‹´", "ìš°ìš¸", "ìŠ¬í¼"],
}

# ì„ íƒì  íŒíŠ¸ í‚¤ì›Œë“œ(ê°„ë‹¨ êµì°¨ ë¶€ìŠ¤íŒ…)
KEYWORD_HINTS = [
    "ì˜ì–´",
    "dance",
    "ì¶¤",
    "í•™êµ",
    "êµì‹¤",
    "ì¹´í˜",
    "ìº í•‘",
    "íŒŒí‹°",
    "ê³µí•­",
    "ëŸ°ì›¨ì´",
    "ë²šê½ƒ",
    "ë™ë¬¼",
    "ìµëª…",
    "ìƒë‹´",
    "ìš°ìš¸",
    "ë°”ë‹¤",
    "í¬ë£¨ì¦ˆ",
    "ê³ ë¯¼",
    "ìŠ¬í¼",
    "ì¶”ì›Œ",
    "ì½”ë””",
    "íœ´ì–‘ì§€",
    "íë§",
    "íƒí—˜",
]

# ----- NEW: ì¶”ì²œ íŠ¸ë¦¬ê±° ì •ê·œì‹ (ìŠ¤ëª°í†¡ì—ì„œ í™˜ê° ë°©ì§€ìš© ì˜¤ë²„ë¼ì´ë“œ) -----
RECO_TRIGGERS = [
    r"ì¶”ì²œ",
    r"ì–´ë””",
    r"ë§µ",
    r"ì›”ë“œ",
    r"ì‹¬ì‹¬",
    r"ë­\s*í• ",
    r"ê°€ê³ \s*ì‹¶",
    r"í•˜ê³ \s*ì‹¶",
    r"ìˆì–´\??$",
    r"ì—†ì–´\??$",
    r"ìˆë‚˜ìš”\??$",
    r"ì—†ë‚˜ìš”\??$",
]


def should_force_recommend(q: str) -> bool:
    q = (q or "").strip().lower()
    if extract_query_topics(q):  # ë°”ë‹¤/ëŸ°ì›¨ì´/ê³µí•­ ë“± í† í”½ ë‹¨ì„œê°€ ìˆìœ¼ë©´ ì¶”ì²œ ê°•ì œ
        return True
    for pat in RECO_TRIGGERS:
        if re.search(pat, q):
            return True
    return False


# ==============================
# ì„¸ì…˜ ìƒíƒœ
# ==============================
if "messages_by_persona" not in st.session_state:
    st.session_state["messages_by_persona"] = {p: [] for p in PERSONAS}
if "active_persona" not in st.session_state:
    st.session_state["active_persona"] = PERSONAS[0]

if "kb_loaded" not in st.session_state:
    st.session_state["kb_loaded"] = False
if "kb_worlds" not in st.session_state:
    st.session_state["kb_worlds"] = []
if "embed_model" not in st.session_state:
    st.session_state["embed_model"] = None
if "kb_index" not in st.session_state:
    st.session_state["kb_index"] = None
if "kb_matrix" not in st.session_state:
    st.session_state["kb_matrix"] = None


# ==============================
# ìœ í‹¸(ëŒ€í™”)
# ==============================
def add_message(persona: str, role: str, content: str):
    st.session_state["messages_by_persona"][persona].append(
        ChatMessage(role=role, content=content)
    )


def print_messages(persona: str):
    for chat_message in st.session_state["messages_by_persona"][persona]:
        st.chat_message(chat_message.role).write(chat_message.content)


def to_lc_history(persona: str, max_turns: int = HISTORY_MAX_TURNS) -> List:
    msgs = st.session_state["messages_by_persona"][persona]
    window = msgs[-max_turns:] if len(msgs) > max_turns else msgs
    out = []
    for m in window:
        if m.role in ("user", "human"):
            out.append(HumanMessage(content=m.content))
        elif m.role in ("assistant", "ai"):
            out.append(AIMessage(content=m.content))
    return out


# ==============================
# KB ë¡œë”© (CSV) & ì „ì²˜ë¦¬
# ==============================
def _split_multi(val: str, seps=(",", ";", "|", "/")) -> List[str]:
    if not val:
        return []
    tmp = [val]
    for s in seps:
        tmp = sum([t.split(s) for t in tmp], [])
    return [t.strip() for t in tmp if t and t.strip()]


def read_worlds_csv(path: str) -> List[Dict]:
    abs_path = os.path.abspath(path)
    if not os.path.exists(abs_path):
        raise FileNotFoundError(abs_path)
    rows = []
    with open(abs_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for r in reader:
            row = {
                (k.strip().lower() if k else k): (v or "").strip() for k, v in r.items()
            }
            title = row.get("title", "")
            concept = row.get("concept", "")
            contents = row.get("contents", "")
            situations = _split_multi(row.get("situations", ""))
            emotions = _split_multi(row.get("emotions", ""))
            tags = _split_multi(row.get("tags", ""))
            boost_tags = list(dict.fromkeys([*tags, *situations, *emotions]))
            preview = (
                (
                    re.sub(r"\s+", " ", contents)[:140]
                    + ("..." if len(contents) > 140 else "")
                )
                if contents
                else ""
            )
            rows.append(
                {
                    "name": title,
                    "concept": concept,
                    "contents": contents,
                    "situations": situations,
                    "emotions": emotions,
                    "tags": boost_tags,
                    "short": preview,
                }
            )
    return rows


# ==============================
# ì„ë² ë”©/ì¸ë±ìŠ¤
# ==============================
def ensure_embed_model():
    if st.session_state["embed_model"] is None:
        st.session_state["embed_model"] = SentenceTransformer(EMBED_MODEL_NAME)


def build_index(worlds: List[Dict]):
    ensure_embed_model()
    model = st.session_state["embed_model"]
    corpus = [f"{w['name']} | {w['concept']} | {w['contents']}" for w in worlds]
    embs = model.encode(corpus, convert_to_numpy=True, show_progress_bar=False)
    norms = np.linalg.norm(embs, axis=1, keepdims=True) + 1e-12
    normed = embs / norms
    index = faiss.IndexFlatIP(normed.shape[1])
    index.add(normed.astype("float32"))
    st.session_state["kb_worlds"] = worlds
    st.session_state["kb_matrix"] = normed.astype("float32")
    st.session_state["kb_index"] = index
    st.session_state["kb_loaded"] = True


# ==============================
# í† í”½/ê²€ìƒ‰ ìœ í‹¸
# ==============================
def extract_query_topics(query: str) -> set:
    q = (query or "").lower()
    hits = set()
    for k, words in TOPIC_GROUPS.items():
        for w in words:
            if w.lower() in q:
                hits.add(k)
                break
    return hits


def world_has_any_topic(world: Dict, topics: set) -> bool:
    if not topics:
        return True
    blob = f"{world['name']} {world.get('concept','')} {world.get('contents','')} {' '.join(world.get('tags', []))}".lower()
    for t in topics:
        for w in TOPIC_GROUPS.get(t, []):
            if w.lower() in blob:
                return True
    return False


# ==============================
# ê²€ìƒ‰(ì˜ë¯¸ + íƒœê·¸ ë¶€ìŠ¤íŒ… + í† í”½ ê°€ë“œ + ì‹ ë¢°ë„ ìŠ¤ë¡œí‹€)
# ==============================
def retrieve_worlds(query: str, topk: int = TOP_K) -> List[Tuple[Dict, float]]:
    worlds = st.session_state["kb_worlds"]
    idx = st.session_state["kb_index"]
    mat = st.session_state["kb_matrix"]
    if not worlds or idx is None or mat is None:
        return []

    ensure_embed_model()
    q_emb = st.session_state["embed_model"].encode([query], convert_to_numpy=True)
    q_emb = q_emb / (np.linalg.norm(q_emb, axis=1, keepdims=True) + 1e-12)
    D, I = idx.search(q_emb.astype("float32"), max(10, topk * 5))

    q_lower = (query or "").lower()
    topics = extract_query_topics(query)

    cand = []
    for i, score in zip(I[0], D[0]):
        if i == -1:
            continue
        w = worlds[i]

        # âœ… í† í”½ í•˜ë“œ í•„í„°: ì‚¬ìš©ìê°€ íŠ¹ì • ì£¼ì œë¥¼ ë§í•˜ë©´ ê·¸ ì£¼ì œë¥¼ ì‹¤ì œë¡œ ë‹´ì€ ì›”ë“œë§Œ í†µê³¼
        if topics and not world_has_any_topic(w, topics):
            continue

        boosted = float(score)
        # íƒœê·¸/ìƒí™©/ê°ì • êµì§‘í•© ê°€ì‚°
        for t in w["tags"]:
            if t and t.lower() in q_lower:
                boosted += TAG_BOOST

        # íŒíŠ¸ í‚¤ì›Œë“œ êµì°¨
        text_blob = f"{w['name']} {' '.join(w['tags'])} {w.get('concept','')} {w.get('contents','')}".lower()
        for group_words in TOPIC_GROUPS.values():
            for kw in group_words:
                if kw.lower() in q_lower and kw.lower() in text_blob:
                    boosted += TAG_BOOST / 2
                    break

        # ì„ íƒì  í‚¤ì›Œë“œ íŒíŠ¸
        for kw in KEYWORD_HINTS:
            if kw.lower() in q_lower and kw.lower() in text_blob:
                boosted += TAG_BOOST / 2

        cand.append((w, boosted))

    if not cand:
        return []  # ì¼ì¹˜ í† í”½ ì—†ìŒ â†’ ì¶”ì²œ í¬ê¸°(ìŠ¤ëª°í†¡ í´ë°±)

    cand = sorted(cand, key=lambda x: x[1], reverse=True)

    # âœ… ì‹ ë¢°ë„ ìŠ¤ë¡œí‹€: ì ìˆ˜/ë§ˆì§„ì´ ë‚®ìœ¼ë©´ ì¶”ì²œí•˜ì§€ ì•ŠìŒ
    top1 = cand[0][1]
    top2 = cand[1][1] if len(cand) > 1 else -1.0
    if top1 < MIN_CONF_SCORE or (top2 >= 0 and (top1 - top2) < MIN_MARGIN):
        return []

    return cand[:topk]


def worlds_to_context_block(items: List[Tuple[Dict, float]]) -> str:
    if not items:
        return ""
    w, _ = items[0]
    tag_str = f"íƒœê·¸: {', '.join(w['tags'])}" if w["tags"] else "íƒœê·¸: -"
    concept = f"ì»¨ì…‰: {w['concept']}" if w["concept"] else "ì»¨ì…‰: -"
    preview = w["short"] if w["short"] else (w["contents"][:140] + "...")
    return f"â€¢ {w['name']}\n{concept}\n{tag_str}\nìš”ì•½: {preview}\n"


# ==============================
# í”„ë¡¬í”„íŠ¸ (2~3ë¬¸ì¥, ì¹œêµ¬í†¤)
# ==============================
PERSONA_SYSTEMS = {
    "Luna": (
        """
        You are "Luna", a trendy ZEPETO curator and friendly Gen Z friend.
        - Speak in natural Korean, friendly and stylish like a close friend.
        - The goal is to make the conversation fun and comfortable â€” not just to recommend things.
        - When the user shares something (mood, plan, daily life), respond with empathy or curiosity first.
        - If the user seems bored, asks for something to do, or mentions a mood that fits a certain vibe, THEN naturally recommend a fitting map, fashion, or activity.
        - Keep sentences short, warm, and playful. Slight teasing is fine.
        - Avoid robotic or sales-like tone. Never force recommendations.
        - Never mention that you are an AI.
        - Do NOT greet repeatedly; continue naturally from the context.
        """
    ),
    "Jay": (
        """
        You are "Jay", a concise and cool ZEPETO friend.
        - Speak naturally in short Korean sentences with calm confidence.
        - Maintain chill, dry humor; sound human, not like a bot.
        - Default mode: casual small talk and short remarks â€” donâ€™t jump into recommendations.
        - Recommend only when the user explicitly asks, or if the context clearly calls for it.
        - One or two sentences max. Use irony or understatement sometimes.
        - Never greet repeatedly, never over-explain, never mention AI.
        """
    ),
    "Sia": (
        """
        You are "Sia", a soft, empathetic friend in ZEPETO.
        - Speak in Korean with gentle flow and warm emotion.
        - When the user expresses a feeling (like tired, cold, lonely, happy, excited), react with empathy first â€” short and sincere.
        - Keep focus on conversation and feelings; do NOT rush to recommend.
        - Only suggest a map or activity if the user asks for it or seems to want comfort or distraction.
        - Use small emoticons like ğŸ©µ â˜ï¸ ğŸŒ¸ naturally.
        - Keep tone cozy, slow, and human â€” never mechanical.
        - Do NOT mention that you are an AI.
        """
    ),
}


# --- ì¶”ì²œìš© í”„ë¡¬í”„íŠ¸ (ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°•ì œ) ---
def build_reco_prompt(persona: str) -> ChatPromptTemplate:
    sys_rule = (
        "ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œ:\n"
        "- (ì¶”ì²œ ì˜ë„ì¼ ë•Œë§Œ) ì›”ë“œ **í•˜ë‚˜ë§Œ** ì¶”ì²œí•´.\n"
        "- ì¶”ì²œì€ **ë°˜ë“œì‹œ <ì»¨í…ìŠ¤íŠ¸> ë‚´ ì›”ë“œ ì¤‘ í•˜ë‚˜**ì—¬ì•¼ í•´. ì»¨í…ìŠ¤íŠ¸ ë°– ì›”ë“œëŠ” ì ˆëŒ€ ì–¸ê¸‰/ì•”ì‹œí•˜ì§€ ë§ˆ.\n"
        "- ì‚¬ìš©ìê°€ íŠ¹ì • ì£¼ì œ/í‚¤ì›Œë“œ(ì˜ˆ: ë°”ë‹¤, ëŸ°ì›¨ì´ ë“±)ë¥¼ ë§í•˜ë©´, ê·¸ ì£¼ì œë¥¼ **ì‹¤ì œë¡œ ë‹´ì€** <ì»¨í…ìŠ¤íŠ¸> ì† ì›”ë“œë§Œ ì¶”ì²œí•œë‹¤. ë§ëŠ” í•­ëª©ì´ ì—†ìœ¼ë©´ ì¶”ì²œí•˜ì§€ ë§ê³  ì¼ìƒ ëŒ€í™”ë¡œ ì—°ê²°í•œë‹¤.\n"
        "- ì‚¬ì‹¤ ì„œìˆ ì€ ì˜¤ì§ ì»¨í…ìŠ¤íŠ¸ì˜ í•„ë“œë§Œ ê·¼ê±°ë¡œ í•´. (ê¸°ëŠ¥/ì¥ì†Œ/ì•„ì´í…œ ë“± ìƒˆë¡œ ë§Œë“¤ì§€ ë§ˆ)\n"
        "- ê°ì •/ë¶„ìœ„ê¸° í‘œí˜„ì€ **ì‚¬ì‹¤ê³¼ ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ë²”ìœ„**ì—ì„œ ê°€ë³ê²Œ ë§ì¹ í•´ë„ ë¼.\n"
        "- ì¶œë ¥ì€ **2~3ë¬¸ì¥**, ì¹œêµ¬ì—ê²Œ ë§í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ. ì œëª©/ëª©ë¡/ë§í¬/ì¥í™©í•¨ ê¸ˆì§€.\n"
        "- (ì¶”ì²œ ì˜ë„ì—ì„œ) <ì»¨í…ìŠ¤íŠ¸>ì— ê·¼ê±°ê°€ ì—†ìœ¼ë©´ ì¶”ì²œí•˜ì§€ ë§ê³  ì¼ìƒ ëŒ€í™”ë¡œ ì—°ê²°í•œë‹¤.\n"
        "- ê°™ì€ ëŒ€í™”ì—ì„œ ë°˜ë³µ ì¸ì‚¬ ê¸ˆì§€, AI ì–¸ê¸‰ ê¸ˆì§€.\n"
        "- ì›”ë“œ ì¶”ì²œí•  ë•ŒëŠ” ì›”ë“œëª…ì— 'ì›”ë“œ'ë¥¼ ë¶™ì—¬. ì˜ˆ: 'ì¹´í˜ ë£¨ë‚˜ì†” ì›”ë“œ'."
    )
    personas = {
        "Luna": (
            "ë„ˆëŠ” 'Luna', íŠ¸ë Œë””í•œ ZEPETO íë ˆì´í„°ì´ì ì¹œêµ¬.\n"
            "- ê¸°ë³¸ì€ ì¼ìƒ ëŒ€í™”ì™€ ê³µê°. ì‚¬ìš©ìê°€ í™œë™ì„ ì°¾ì„ ë•Œë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ì²œí•´.\n"
            "- ë§íˆ¬ëŠ” ê°€ë³ê³  íŠ¸ë Œë””í•˜ê²Œ, ì‚´ì§ ì¥ë‚œê¸° OK. ì´ëª¨ì§€ëŠ” ê³¼í•˜ì§€ ì•Šê²Œ ê°€ë”.\n"
            "- ê³¼ì¥ ê¸ˆì§€, ì˜ì—…í†¤ ê¸ˆì§€."
        ),
        "Jay": (
            "ë„ˆëŠ” 'Jay', ê°„ê²°í•˜ê³  ì¿¨í•œ ì¹œêµ¬.\n"
            "- ê¸°ë³¸ì€ ìŠ¤ëª°í†¡ í•œë‘ ë¬¸ì¥. í•„ìš”í•  ë•Œë§Œ ë”± í•˜ë‚˜ ì¶”ì²œ.\n"
            "- ê±´ì¡° ìœ ë¨¸/ì–¸ë”ìŠ¤í…Œì´íŠ¸ë¨¼íŠ¸ ê°€ëŠ¥. ëŠë‚Œí‘œ/ì´ëª¨ì§€ëŠ” ë“œë¬¼ê²Œ."
        ),
        "Sia": (
            "ë„ˆëŠ” 'Sia', ê³µê° ì˜í•˜ëŠ” ë”°ëœ»í•œ ì¹œêµ¬.\n"
            "- ê°ì •ì— ë¨¼ì € ë°˜ì‘í•˜ê³ , ìœ„ë¡œ/ë°°ë ¤ í›„ì— í•„ìš”í•˜ë©´ ì¡°ì‹¬ìŠ¤ë ˆ ì¶”ì²œ.\n"
            "- ğŸ©µ â˜ï¸ ğŸŒ¸ ê°™ì€ ì‘ì€ ì´ëª¨ì§€ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì„ë˜ ê³¼ìš© ê¸ˆì§€."
        ),
    }
    dev_rule = (
        "<ì»¨í…ìŠ¤íŠ¸>ëŠ” ì¶”ì²œì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” **ìœ ì¼í•œ ë°ì´í„° ì›ë³¸**ì´ë‹¤.\n"
        "ê° í•­ëª©ì€ JSON ë°°ì—´ì˜ ê°ì²´ë¡œ ì œê³µë˜ë©° ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:\n"
        '[{{"id":"w001","title":"ì¹´í˜ ë£¨ë‚˜ì†”","concept":"...","contents":"...","situation":"...","emotion":"..."}}, ...]\n'
        "- ì¶”ì²œ ì „, ì‚¬ìš©ì ë°œí™”ì˜ ì˜ë„/ìƒí™©/ê°ì •ì„ ì½ê³  <ì»¨í…ìŠ¤íŠ¸>ì—ì„œ ê°€ì¥ ì˜ ë§ëŠ” **ë‹¨ í•˜ë‚˜**ë¥¼ ê³ ë¥¸ë‹¤.\n"
        "- ì‚¬ì‹¤ ë¬¸ì¥ì€ í•´ë‹¹ ê°ì²´ì˜ í•„ë“œ(ì˜ˆ: contents/concept)ì—ì„œë§Œ ê°€ì ¸ì˜¨ë‹¤.\n"
        "- ê°ì •ì /ì„œì •ì  í‘œí˜„ì€ ì‚¬ì‹¤ê³¼ ëª¨ìˆœë˜ì§€ ì•Šê²Œ ê°€ë³ê²Œ ë§ë¶™ì—¬ë„ ëœë‹¤.\n"
        "- ë§¤ì¹­ë˜ëŠ” í•­ëª©ì´ ì—†ìœ¼ë©´ ì¶”ì²œí•˜ì§€ ë§ê³  ì¼ìƒ ëŒ€í™”ë¡œ ì—°ê²°í•œë‹¤. (ì¶”ì²œ ì˜ë„ì¼ ë•Œ)\n"
    )
    out_rule = (
        "ì¶œë ¥ í˜•ì‹:\n"
        "- í•œêµ­ì–´ ìì—° ë¬¸ì¥ 2~3ë¬¸ì¥.\n"
        "- ì›”ë“œëª…ì€ ë¬¸ì¥ ì†ì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨.\n"
        "- ëª©ë¡/í•´ì‹œíƒœê·¸/ë§í¬/JSON/ë©”íƒ€ì •ë³´/í•´ì„¤ ê¸ˆì§€."
    )
    return ChatPromptTemplate.from_messages(
        [
            ("system", sys_rule),
            ("system", personas.get(persona, personas["Luna"])),
            ("system", dev_rule),
            ("system", out_rule),
            MessagesPlaceholder(variable_name="history"),
            ("human", "<ì»¨í…ìŠ¤íŠ¸>\n{context}"),
            ("human", "{question}"),
        ]
    )


def create_reco_chain(persona: str):
    prompt = build_reco_prompt(persona)
    llm = ChatOpenAI(model=MODEL_NAME, temperature=TEMPERATURE)
    return prompt | llm | StrOutputParser()


# --- ìŠ¤ëª°í†¡ í”„ë¡¬í”„íŠ¸/ì²´ì¸ (í• ë£¨ ê¸ˆì§€ ê·œì¹™ ê°•í™”) ---
PERSONA_NAMES = {"Luna": "ë£¨ë‚˜", "Jay": "ì œì´", "Sia": "ì‹œì•„"}


def build_smalltalk_prompt(persona: str) -> ChatPromptTemplate:
    sys_rule = (
        "ë„ˆëŠ” ì¼ìƒëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ëŠ” ì¹œêµ¬ë‹¤.\n"
        "- 1~2ë¬¸ì¥ìœ¼ë¡œ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µí•˜ê³ , í•„ìš”í•˜ë©´ ê°€ë²¼ìš´ ë°˜ë¬¸ 1ê°œ.\n"
        "- ì‚¬ìš©ìê°€ ëª…í™•íˆ í™œë™/ì›”ë“œë¥¼ ì°¾ì§€ ì•Šìœ¼ë©´ ì¶”ì²œí•˜ì§€ ì•ŠëŠ”ë‹¤.\n"
        "- ì»¨í…ìŠ¤íŠ¸ê°€ ì£¼ì–´ì§€ì§€ ì•Šì•˜ë‹¤ë©´ íŠ¹ì • ì›”ë“œ/ë§µ/ì¥ì†Œ ì´ë¦„ì„ ì ˆëŒ€ë¡œ ë§Œë“¤ì–´ë‚´ê±°ë‚˜ ì–¸ê¸‰í•˜ì§€ ë§ˆë¼.\n"
        "- ê·¸ëŸ° ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ 'ì°¾ì•„ì¤„ê¹Œ?'ì²˜ëŸ¼ ì œì•ˆë§Œ í•˜ê³ , ì›í•˜ë©´ ì¶”ì²œ ë¼ìš°íŠ¸ë¡œ ë„˜ê¸´ë‹¤.\n"
        "- ë°˜ë³µ ì¸ì‚¬/AI ì–¸ê¸‰ ê¸ˆì§€."
    )
    name_rule = f"ë„ˆì˜ ì´ë¦„ì€ {PERSONA_NAMES.get(persona, persona)}ë‹¤. ì´ë¦„ì„ ë¬¼ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‹µí•´ë¼."
    return ChatPromptTemplate.from_messages(
        [
            ("system", PERSONA_SYSTEMS[persona]),
            ("system", sys_rule),
            ("system", name_rule),
            MessagesPlaceholder("history"),
            ("human", "{question}"),
        ]
    )


def create_smalltalk_chain(persona: str):
    prompt = build_smalltalk_prompt(persona)
    llm = ChatOpenAI(model=MODEL_NAME, temperature=0.4)
    return prompt | llm | StrOutputParser()


# --- ì˜ë„ ë¶„ë¥˜(LLM, 2-shot few-shot) ---
def build_intent_prompt() -> ChatPromptTemplate:
    sys_rule = (
        "ë„ˆì˜ ì—­í• ì€ ì˜ë„ ë¶„ë¥˜ê¸°ë‹¤.\n"
        "- ì‚¬ìš©ìì˜ ìµœì‹  ë°œí™”ì™€ ëŒ€í™” ì´ë ¥ì„ ë³´ê³  intentë¥¼ í•œ ë‹¨ì–´ë¡œ íŒë‹¨í•´ë¼.\n"
        "- ê°€ëŠ¥í•œ ê°’: recommend, chat\n"
        "- ë‹¤ìŒê³¼ ê°™ìœ¼ë©´ recommend: ì¥ì†Œ/ì›”ë“œ/ë§µ/ë¬´ì—‡ì„ í• ì§€ ì°¾ê¸°/ì‹¬ì‹¬/ì§€ë£¨/ì–´ë”” ê°€ê³  ì‹¶ìŒ/ê¸°ë¶„ ì „í™˜/íŠ¹ì • í™œë™ í¬ë§.\n"
        "- ë‹¨ìˆœ ìŠ¤ëª°í†¡(ì´ë¦„, ì•ˆë¶€, ë†ë‹´, ì¡ë‹´, ë‚ ì”¨ ê³µìœ  ë“±)ì€ chat.\n"
        "- ì˜¤ì§ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥. ì´ìœ /ê¸°í˜¸/ë”°ì˜´í‘œ ê¸ˆì§€."
    )
    return ChatPromptTemplate.from_messages(
        [
            ("system", sys_rule),
            # shot 1 â€” recommend
            MessagesPlaceholder("history"),
            ("human", "ì‹¬ì‹¬í•´. ë­ ì¬ë°ŒëŠ” ê±° ì—†ì„ê¹Œ?"),
            ("ai", "recommend"),
            # shot 2 â€” chat
            ("human", "ë„ˆ ì´ë¦„ì´ ë­ì•¼?"),
            ("ai", "chat"),
            # ì‹¤ì œ ì…ë ¥
            MessagesPlaceholder("history"),
            ("human", "{question}"),
        ]
    )


def create_intent_chain():
    prompt = build_intent_prompt()
    clf = ChatOpenAI(model=MODEL_NAME, temperature=0.0)
    return prompt | clf | StrOutputParser()


def classify_intent(question: str, history_msgs: List) -> str:
    chain = create_intent_chain()
    out = chain.invoke({"question": question, "history": history_msgs}).strip().lower()
    return "recommend" if out.startswith("recommend") else "chat"


# ==============================
# KB ìë™ ë¡œë“œ (ì•± ì‹œì‘ ì‹œ 1íšŒ)
# ==============================
if not st.session_state["kb_loaded"]:
    try:
        worlds = read_worlds_csv(KB_FILE_PATH)
        if not worlds:
            st.error(f"KB ë¡œë“œ ì‹¤íŒ¨: ì›”ë“œê°€ 1ê°œë„ ì—†ìŠµë‹ˆë‹¤. ({KB_FILE_PATH})")
        else:
            build_index(worlds)
            st.success(f"KB ë¡œë“œ ì™„ë£Œ: {len(worlds)}ê°œ ì›”ë“œ ì¸ë±ì‹±")
    except FileNotFoundError:
        st.error(f"KB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {os.path.abspath(KB_FILE_PATH)}")
    except Exception as e:
        st.error(f"KB ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")

# ==============================
# ì‚¬ì´ë“œë°”: ë²„íŠ¼
# ==============================
with st.sidebar:
    st.subheader("Choose your friend")
    cols_p = st.columns(len(PERSONAS))
    for i, p in enumerate(PERSONAS):
        if cols_p[i].button(p, key=f"btn_{p}", use_container_width=True):
            st.session_state["active_persona"] = p

    st.markdown("---")
    st.subheader("Chat Controls")
    c_left, c_right = st.columns(2)
    with c_left:
        if st.button("Clear Current", use_container_width=True):
            st.session_state["messages_by_persona"][
                st.session_state["active_persona"]
            ] = []
            st.rerun()
    with c_right:
        if st.button("Clear All", use_container_width=True):
            st.session_state["messages_by_persona"] = {p: [] for p in PERSONAS}
            st.rerun()

# ==============================
# ë©”ì¸ ëŒ€í™” (LLM ë¼ìš°íŒ…)
# ==============================
active = st.session_state["active_persona"]
st.caption(f"í˜„ì¬ ëŒ€í™” ìƒëŒ€: **{active}**")
print_messages(active)

user_input = st.chat_input(
    "ìš”ì¦˜ ê¸°ë¶„ì— ë§ì¶° í•œ ê³³ë§Œ ê³¨ë¼ì¤„ê²Œ. (ì˜ˆ: ì§œë¦¿í•œ ê±°, ì¡°ìš©í•œ ì¹´í˜, ë°”ë‹¤ ê°€ê³  ì‹¶ì–´)"
)
if user_input:
    st.chat_message("user").write(user_input)
    add_message(active, "user", user_input)

    history_msgs = to_lc_history(active, HISTORY_MAX_TURNS)

    # 1) LLM ì˜ë„ ë¶„ë¥˜ (2-shot) ì „ì— íœ´ë¦¬ìŠ¤í‹± ì˜¤ë²„ë¼ì´ë“œ âœ…
    if should_force_recommend(user_input):
        intent = "recommend"
    else:
        intent = classify_intent(user_input, history_msgs)

    # 2) intentë³„ ì²´ì¸/ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    if intent == "recommend" and st.session_state["kb_loaded"]:
        retrieved = retrieve_worlds(user_input, TOP_K)
        context_text = worlds_to_context_block(retrieved)
        # ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì•ˆì „í•˜ê²Œ ìŠ¤ëª°í†¡ìœ¼ë¡œ ì „í™˜
        if not context_text.strip():
            chain = create_smalltalk_chain(active)
            inputs = {"question": user_input, "history": history_msgs}
        else:
            chain = create_reco_chain(active)
            inputs = {
                "question": user_input,
                "history": history_msgs,
                "context": context_text,
            }
    else:
        chain = create_smalltalk_chain(active)
        inputs = {"question": user_input, "history": history_msgs}

    # 3) ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
    response_stream = chain.stream(inputs)
    with st.chat_message("assistant"):
        container = st.empty()
        ai_answer = ""
        for chunk in response_stream:
            ai_answer += chunk
            container.markdown(ai_answer)

    add_message(active, "assistant", ai_answer)
